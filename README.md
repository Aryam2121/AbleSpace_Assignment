# Product Data Explorer

A production-minded product exploration platform that enables users to navigate from high-level headings â†’ categories â†’ products â†’ product detail pages, powered by live, on-demand scraping from World of Books.

## ğŸ—ï¸ Architecture Overview

### Tech Stack

**Frontend:**
- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
- SWR for data fetching
- Axios for API calls

**Backend:**
- NestJS
- TypeScript
- PostgreSQL with Prisma ORM
- Bull Queue for job processing
- Redis for caching
- Crawlee + Playwright for scraping

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚      â”‚              â”‚      â”‚             â”‚
â”‚   Next.js   â”‚â”€â”€â”€â”€â”€â–¶â”‚   NestJS     â”‚â”€â”€â”€â”€â”€â–¶â”‚ PostgreSQL  â”‚
â”‚  Frontend   â”‚      â”‚   Backend    â”‚      â”‚  Database   â”‚
â”‚             â”‚      â”‚              â”‚      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚              â”‚
                     â”‚  Bull Queue  â”‚
                     â”‚   + Redis    â”‚
                     â”‚              â”‚
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚              â”‚
                     â”‚   Crawlee    â”‚
                     â”‚  + Playwrightâ”‚
                     â”‚              â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ 
- Docker & Docker Compose
- PostgreSQL 14+ (if running without Docker)
- Redis (if running without Docker)

### Running with Docker (Recommended)

```bash
# Clone the repository
git clone <your-repo-url>
cd product-data-explorer

# Start all services
docker-compose up -d

# Run database migrations
docker-compose exec backend npm run prisma:migrate

# Seed initial data (optional)
docker-compose exec backend npm run seed

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:3001
# API Docs: http://localhost:3001/api
```

### Running Locally

#### Backend Setup

```bash
cd backend

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env
# Edit .env with your configuration

# Run database migrations
npm run prisma:migrate

# Start the development server
npm run start:dev

# Backend runs on http://localhost:3001
```

#### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env.local
# Edit .env.local with your API URL

# Start the development server
npm run dev

# Frontend runs on http://localhost:3000
```

## ğŸ“ Project Structure

```
product-data-explorer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ navigation/          # Navigation headings module
â”‚   â”‚   â”œâ”€â”€ category/            # Categories module
â”‚   â”‚   â”œâ”€â”€ product/             # Products module
â”‚   â”‚   â”œâ”€â”€ scraping/            # Scraping service with Crawlee
â”‚   â”‚   â”œâ”€â”€ queue/               # Bull queue configuration
â”‚   â”‚   â”œâ”€â”€ cache/               # Redis caching service
â”‚   â”‚   â”œâ”€â”€ history/             # View history tracking
â”‚   â”‚   â””â”€â”€ common/              # Shared utilities, DTOs, guards
â”‚   â”œâ”€â”€ prisma/
â”‚   â”‚   â”œâ”€â”€ schema.prisma        # Database schema
â”‚   â”‚   â””â”€â”€ migrations/          # Migration files
â”‚   â”œâ”€â”€ test/                    # E2E tests
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                 # Next.js App Router pages
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx         # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ categories/      # Category pages
â”‚   â”‚   â”‚   â”œâ”€â”€ products/        # Product pages
â”‚   â”‚   â”‚   â””â”€â”€ about/           # About/Contact
â”‚   â”‚   â”œâ”€â”€ components/          # Reusable components
â”‚   â”‚   â”œâ”€â”€ lib/                 # Utilities and API client
â”‚   â”‚   â””â”€â”€ hooks/               # Custom React hooks
â”‚   â”œâ”€â”€ public/                  # Static assets
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml               # CI/CD pipeline
â””â”€â”€ README.md
```

## ğŸ—„ï¸ Database Schema

### Core Entities

**navigation** - Top-level navigation headings
- id, title, slug, last_scraped_at, created_at, updated_at

**category** - Product categories and subcategories
- id, navigation_id, parent_id, title, slug, product_count, last_scraped_at, created_at, updated_at

**product** - Product listings
- id, source_id, category_id, title, price, currency, image_url, source_url, last_scraped_at, created_at, updated_at

**product_detail** - Extended product information
- id, product_id, description, specs, ratings_avg, reviews_count, created_at, updated_at

**review** - Product reviews
- id, product_id, author, rating, text, created_at

**scrape_job** - Scraping job tracking
- id, target_url, target_type, status, started_at, finished_at, error_log, attempts

**view_history** - User navigation history
- id, user_id, session_id, path_json, created_at

## ğŸ”Œ API Documentation

### Base URL
- Development: `http://localhost:3001/api`
- Production: `<your-deployed-backend-url>/api`

### Endpoints

#### Navigation
- `GET /navigation` - List all navigation headings
- `GET /navigation/:slug` - Get specific navigation with categories
- `POST /navigation/:slug/scrape` - Trigger on-demand scrape

#### Categories
- `GET /categories` - List all categories
- `GET /categories/:slug` - Get specific category with products
- `POST /categories/:slug/scrape` - Trigger category scrape

#### Products
- `GET /products` - List products with pagination and filters
  - Query params: `page`, `limit`, `category`, `minPrice`, `maxPrice`, `search`
- `GET /products/:id` - Get product details
- `POST /products/:id/scrape` - Refresh product data

#### History
- `POST /history` - Record view history
- `GET /history/:sessionId` - Get user's browsing history

#### Health
- `GET /health` - API health check

### Swagger Documentation
Visit `http://localhost:3001/api` when the backend is running.

## ğŸ•·ï¸ Scraping Strategy

### Ethical Scraping Practices

1. **Rate Limiting**: Delays between requests (1-3 seconds)
2. **Caching**: DB-backed TTL (default: 24 hours)
3. **Backoff**: Exponential backoff on errors
4. **User Agent**: Proper user agent identification
5. **Respect robots.txt**: Compliant with World of Books policies

### Scraping Flow

```
User Request
    â†“
Check Cache (DB last_scraped_at)
    â†“
Cache Hit? â†’ Return Cached Data
    â†“
Cache Miss
    â†“
Queue Scraping Job (Bull)
    â†“
Worker Process Job (Crawlee + Playwright)
    â†“
Parse & Validate Data
    â†“
Store in PostgreSQL
    â†“
Return Fresh Data
```

### Deduplication

- Products identified by `source_id` (unique constraint)
- Categories by `slug` within navigation context
- Reviews by combination of product + author + text hash

## ğŸ¨ Frontend Features

### Pages

1. **Landing (/)** - Navigation headings with hero section
2. **Category (/categories/[slug])** - Subcategories and product grid
3. **Products (/products)** - Searchable product listing with filters
4. **Product Detail (/products/[id])** - Full product info, reviews, recommendations
5. **About (/about)** - Project information and contact

### UX Features

- âœ… Responsive design (mobile-first)
- âœ… Loading skeletons
- âœ… Error boundaries
- âœ… Optimistic UI updates
- âœ… Client-side navigation history
- âœ… Accessibility (WCAG AA)
- âœ… Dark mode support (bonus)

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend

# Unit tests
npm run test

# E2E tests
npm run test:e2e

# Test coverage
npm run test:cov
```

### Frontend Tests

```bash
cd frontend

# Unit tests
npm run test

# E2E tests (Playwright)
npm run test:e2e
```

## ğŸš¢ Deployment

### Frontend (Vercel)

```bash
cd frontend
vercel --prod
```

### Backend (Railway/Render)

```bash
cd backend

# Build
npm run build

# Start production
npm run start:prod
```

### Environment Variables

#### Backend (.env)
```env
DATABASE_URL=postgresql://user:password@localhost:5432/product_explorer
REDIS_URL=redis://localhost:6379
PORT=3001
SCRAPING_DELAY_MS=2000
CACHE_TTL_HOURS=24
```

#### Frontend (.env.local)
```env
NEXT_PUBLIC_API_URL=http://localhost:3001/api
```

## ğŸ” Security

- âœ… Input validation with class-validator
- âœ… SQL injection prevention (Prisma ORM)
- âœ… CORS configuration
- âœ… Rate limiting on API endpoints
- âœ… Environment variable security
- âœ… No secrets in repository

## ğŸ“ˆ Performance & Observability

### Caching Strategy

- **Database-level**: `last_scraped_at` timestamps
- **Redis**: Hot data caching with TTL
- **SWR**: Client-side caching and revalidation

### Monitoring

- Winston logger with file rotation
- Request/response logging
- Error tracking and alerting
- Scraping job metrics

## ğŸ¯ Design Decisions

### Why PostgreSQL?
- Relational data (products, categories, reviews)
- ACID compliance for scraping job reliability
- Excellent JSON support for flexible metadata
- Prisma ORM integration

### Why Bull Queue?
- Reliable job processing with Redis
- Automatic retries and backoff
- Job prioritization
- Progress tracking

### Why Crawlee + Playwright?
- Handles JavaScript-heavy sites
- Built-in rate limiting and retries
- Automatic browser management
- TypeScript support

### Why SWR?
- Automatic revalidation
- Optimistic UI updates
- Built-in caching
- Better UX with stale-while-revalidate pattern

## ğŸ› Troubleshooting

### Common Issues

**Scraping fails with timeout:**
- Increase `SCRAPING_TIMEOUT_MS` in .env
- Check network connectivity
- Verify World of Books is accessible

**Database connection errors:**
- Verify PostgreSQL is running
- Check DATABASE_URL format
- Run migrations: `npm run prisma:migrate`

**Redis connection errors:**
- Ensure Redis is running
- Check REDIS_URL configuration

**Build errors:**
- Clear node_modules and reinstall
- Check Node.js version (18+)
- Verify all environment variables

## ğŸ“ License

MIT

## ğŸ‘¥ Contributors

[Your Name]

## ğŸ”— Links

- **Live Frontend**: [Your Vercel URL]
- **Live Backend**: [Your Railway/Render URL]
- **GitHub Repository**: [Your GitHub URL]
- **API Documentation**: [Your Backend URL]/api
